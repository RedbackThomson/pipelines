#!/usr/bin/env bash

set -u
set -o pipefail

usage(){
	echo "Usage: $0 -n <deployment name> [-r <region>]"
	exit 1
}

### Input parameters
DEPLOY_NAME="sagemaker-kfp-"$(date '+%Y-%m-%d-%H-%M-%S')"" # The name given to the entire deployment (tagging all resources)
REGION=`aws configure get region` # Deployment region

### Configuration parameters
EKS_CLUSTER_VERSION="1.15" # EKS cluster K8s version
EKS_NODE_COUNT="1" # The initial node count of the EKS cluster
EKS_PUBLIC_SUBNETS=${EKS_PUBLIC_SUBNETS:-""}
EKS_PRIVATE_SUBNETS=${EKS_PRIVATE_SUBNETS:-""}

### Testing parameters
MINIO_LOCAL_PORT=9000

while getopts ":n:r:" opt; do
  case $opt in
    n)
      DEPLOY_NAME="$OPTARG"
      ;;
    r)
      REGION="$OPTARG"
      ;;
    \?)
      echo "Invalid option: -$OPTARG" >&2
      exit 1
      ;;
    :)
      echo "Option -$OPTARG requires an argument." >&2
      exit 1
      ;;
  esac
done

# Ensure a deployment name was specified
if [ "$DEPLOY_NAME" == "" ]; then
  echo "Missing deployment name"
  usage
  exit 1
fi

cleanup() {
  set +e

  cleanup_kfp
  delete_generated_role
  delete_eks
}

# Set the trap to clean up resources
# In case of error or normal exit delete the cluster
trap cleanup EXIT
set -e

launch_eks() {
  EKS_CLUSTER_NAME="${DEPLOY_NAME}-eks-cluster"

  echo "[Creating EKS] Launching EKS cluster $EKS_CLUSTER_NAME"

  eksctl_args=( --managed --nodes "${EKS_NODE_COUNT}" --node-type=c5.xlarge --timeout=30m --region "${REGION}" --auto-kubeconfig --version "${EKS_CLUSTER_VERSION}" )
  [ ! -z "${EKS_PUBLIC_SUBNETS}" ] && eksctl_args+=( --vpc-public-subnets="${EKS_PUBLIC_SUBNETS}" )
  [ ! -z "${EKS_PRIVATE_SUBNETS}" ] && eksctl_args+=( --vpc-private-subnets="${EKS_PRIVATE_SUBNETS}" )

  eksctl create cluster "${EKS_CLUSTER_NAME}"

  aws eks update-kubeconfig --name "$EKS_CLUSTER_NAME" --region "$REGION"

  echo "[Creating EKS] $EKS_CLUSTER_NAME launched"
}

delete_eks() {
  eksctl delete cluster --name "${EKS_CLUSTER_NAME}"
}

install_kfp() {
  echo "[Installing KFP] Applying KFP manifests"

  PIPELINE_VERSION=0.5.1
  kubectl apply -k github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref=$PIPELINE_VERSION
  kubectl wait --for condition=established --timeout=60s crd/applications.app.k8s.io
  kubectl apply -k github.com/kubeflow/pipelines/manifests/kustomize/env/dev?ref=$PIPELINE_VERSION

  echo "[Installing KFP] Port-forwarding Minio"

  kubectl port-forward -n kubeflow svc/minio-service $MINIO_LOCAL_PORT:9000 &
  MINIO_PID=$!

  echo "[Installing KFP] Minio port-forwarded to ${MINIO_LOCAL_PORT}"
}

function generate_iam_role_name {
  local cluster=$(echo "${cluster_name}" | cut -d'/' -f2)

  OIDC_ROLE_NAME="$(echo "${cluster}-kubeflow-role" | cut -c1-64)"
}

function delete_generated_role {
  # Delete the role associated with the cluster thats being deleted
  aws iam detach-role-policy --role-name "${OIDC_ROLE_NAME}" --policy-arn arn:aws:iam::aws:policy/AmazonSageMakerFullAccess
  aws iam delete-role --role-name "${OIDC_ROLE_NAME}"
}

cleanup_kfp() {
  # Clean up Minio
  if [[ ! -z "${MINIO_PID}" ]]; then
    kill -9 $MINIO_PID
  fi
}

launch_eks
generate_iam_role_name
./generate_iam_role ${EKS_CLUSTER_NAME} ${OIDC_ROLE_NAME} ${REGION} "kubeflow" "pipeline-runner"
install_kfp